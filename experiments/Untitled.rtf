{\rtf1\ansi\ansicpg1252\cocoartf2757
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 scai \
- meta-prompt easy way to adapt agent\
- same setup can be done with fine-tuning; lora\
- will take it more seriously \
- 1 skills 2 more serious\
\
fine-tune based on output of simulations we are running \
fine tune on simulation \
signal: did you do the right thing? \
- how to construct the dataset? \
- fine-tune \
- translate ideas faithfully and compare \
- generate data for supervised fine-tuning; \
\
\
print:\
- how to ask questions / get more information\
- start with fanciest reflexion baseline \
- but add print-style thing \
- can we get better? \
- how to evaluate information seeking more directly?\
- LLMs can ask questions\
- do they ask good questions? \
- how do you evaluate if questions are good? \
- question only useful if information is useful for the system; this is info that should be useful even if system does not evaluate it properly \
- print statement inserter model; calling code llama + gpt 4; do 10 times, top half is good ones, and use finetuning/expert iteration to see if code-llama \
- build code seeking model? llama2}